{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bbox_data_augmentation.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"pkIYO08T9kRm","executionInfo":{"status":"ok","timestamp":1605823322811,"user_tz":420,"elapsed":817,"user":{"displayName":"Benjamin Brokaw","photoUrl":"","userId":"17754752755213511475"}}},"source":["import random\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","import sys\n","import os\n","\n","lib_path = os.path.join(os.path.realpath(\".\"), \"data_aug\")\n","sys.path.append(lib_path)"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pkjHIgI3-qhE"},"source":["## BBox Utilities"]},{"cell_type":"code","metadata":{"id":"6F1Hm63P-t9b","executionInfo":{"status":"ok","timestamp":1605823323151,"user_tz":420,"elapsed":1149,"user":{"displayName":"Benjamin Brokaw","photoUrl":"","userId":"17754752755213511475"}}},"source":["def draw_rect(im, cords, color = None):\n","    \"\"\"Draw the rectangle on the image\n","    \n","    Parameters\n","    ----------\n","    \n","    im : numpy.ndarray\n","        numpy image \n","    \n","    cords: numpy.ndarray\n","        Numpy array containing bounding boxes of shape `N X 4` where N is the \n","        number of bounding boxes and the bounding boxes are represented in the\n","        format `x1 y1 x2 y2`\n","        \n","    Returns\n","    -------\n","    \n","    numpy.ndarray\n","        numpy image with bounding boxes drawn on it\n","        \n","    \"\"\"\n","    \n","    im = im.copy()\n","    \n","    cords = cords.reshape(-1,4)\n","    if not color:\n","        color = [255,255,255]\n","    for cord in cords:\n","        \n","        pt1, pt2 = (cord[0], cord[1]) , (cord[2], cord[3])\n","                \n","        pt1 = int(pt1[0]), int(pt1[1])\n","        pt2 = int(pt2[0]), int(pt2[1])\n","    \n","        im = cv2.rectangle(im.copy(), pt1, pt2, color, int(max(im.shape[:2])/200))\n","    return im\n","\n","\n","def clip_box(bbox, clip_box, alpha):\n","    \"\"\"Clip the bounding boxes to the borders of an image\n","    \n","    Parameters\n","    ----------\n","    \n","    bbox: numpy.ndarray\n","        Numpy array containing bounding boxes of shape `N X 4` where N is the \n","        number of bounding boxes and the bounding boxes are represented in the\n","        format `x1 y1 x2 y2`\n","    \n","    clip_box: numpy.ndarray\n","        An array of shape (4,) specifying the diagonal co-ordinates of the image\n","        The coordinates are represented in the format `x1 y1 x2 y2`\n","        \n","    alpha: float\n","        If the fraction of a bounding box left in the image after being clipped is \n","        less than `alpha` the bounding box is dropped. \n","    \n","    Returns\n","    -------\n","    \n","    numpy.ndarray\n","        Numpy array containing **clipped** bounding boxes of shape `N X 4` where N is the \n","        number of bounding boxes left are being clipped and the bounding boxes are represented in the\n","        format `x1 y1 x2 y2` \n","    \n","    \"\"\"\n","    ar_ = (bbox_area(bbox))\n","    x_min = np.maximum(bbox[:,0], clip_box[0]).reshape(-1,1)\n","    y_min = np.maximum(bbox[:,1], clip_box[1]).reshape(-1,1)\n","    x_max = np.minimum(bbox[:,2], clip_box[2]).reshape(-1,1)\n","    y_max = np.minimum(bbox[:,3], clip_box[3]).reshape(-1,1)\n","    \n","    bbox = np.hstack((x_min, y_min, x_max, y_max, bbox[:,4:]))\n","    \n","    delta_area = ((ar_ - bbox_area(bbox))/ar_)\n","    \n","    mask = (delta_area < (1 - alpha)).astype(int)\n","    \n","    bbox = bbox[mask == 1,:]\n","\n","\n","    return bbox\n","\n","\n","def rotate_im(image, angle):\n","    \"\"\"Rotate the image.\n","    \n","    Rotate the image such that the rotated image is enclosed inside the tightest\n","    rectangle. The area not occupied by the pixels of the original image is colored\n","    black. \n","    \n","    Parameters\n","    ----------\n","    \n","    image : numpy.ndarray\n","        numpy image\n","    \n","    angle : float\n","        angle by which the image is to be rotated\n","    \n","    Returns\n","    -------\n","    \n","    numpy.ndarray\n","        Rotated Image\n","    \n","    \"\"\"\n","    # grab the dimensions of the image and then determine the\n","    # centre\n","    (h, w) = image.shape[:2]\n","    (cX, cY) = (w // 2, h // 2)\n","\n","    # grab the rotation matrix (applying the negative of the\n","    # angle to rotate clockwise), then grab the sine and cosine\n","    # (i.e., the rotation components of the matrix)\n","    M = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n","    cos = np.abs(M[0, 0])\n","    sin = np.abs(M[0, 1])\n","\n","    # compute the new bounding dimensions of the image\n","    nW = int((h * sin) + (w * cos))\n","    nH = int((h * cos) + (w * sin))\n","\n","    # adjust the rotation matrix to take into account translation\n","    M[0, 2] += (nW / 2) - cX\n","    M[1, 2] += (nH / 2) - cY\n","\n","    # perform the actual rotation and return the image\n","    image = cv2.warpAffine(image, M, (nW, nH))\n","\n","#    image = cv2.resize(image, (w,h))\n","    return image\n","\n","def get_corners(bboxes):\n","    \n","    \"\"\"Get corners of bounding boxes\n","    \n","    Parameters\n","    ----------\n","    \n","    bboxes: numpy.ndarray\n","        Numpy array containing bounding boxes of shape `N X 4` where N is the \n","        number of bounding boxes and the bounding boxes are represented in the\n","        format `x1 y1 x2 y2`\n","    \n","    returns\n","    -------\n","    \n","    numpy.ndarray\n","        Numpy array of shape `N x 8` containing N bounding boxes each described by their \n","        corner co-ordinates `x1 y1 x2 y2 x3 y3 x4 y4`      \n","        \n","    \"\"\"\n","    width = (bboxes[:,2] - bboxes[:,0]).reshape(-1,1)\n","    height = (bboxes[:,3] - bboxes[:,1]).reshape(-1,1)\n","    \n","    x1 = bboxes[:,0].reshape(-1,1)\n","    y1 = bboxes[:,1].reshape(-1,1)\n","    \n","    x2 = x1 + width\n","    y2 = y1 \n","    \n","    x3 = x1\n","    y3 = y1 + height\n","    \n","    x4 = bboxes[:,2].reshape(-1,1)\n","    y4 = bboxes[:,3].reshape(-1,1)\n","    \n","    corners = np.hstack((x1,y1,x2,y2,x3,y3,x4,y4))\n","    \n","    return corners\n","\n","def rotate_box(corners,angle,  cx, cy, h, w):\n","    \n","    \"\"\"Rotate the bounding box.\n","    \n","    \n","    Parameters\n","    ----------\n","    \n","    corners : numpy.ndarray\n","        Numpy array of shape `N x 8` containing N bounding boxes each described by their \n","        corner co-ordinates `x1 y1 x2 y2 x3 y3 x4 y4`\n","    \n","    angle : float\n","        angle by which the image is to be rotated\n","        \n","    cx : int\n","        x coordinate of the center of image (about which the box will be rotated)\n","        \n","    cy : int\n","        y coordinate of the center of image (about which the box will be rotated)\n","        \n","    h : int \n","        height of the image\n","        \n","    w : int \n","        width of the image\n","    \n","    Returns\n","    -------\n","    \n","    numpy.ndarray\n","        Numpy array of shape `N x 8` containing N rotated bounding boxes each described by their \n","        corner co-ordinates `x1 y1 x2 y2 x3 y3 x4 y4`\n","    \"\"\"\n","\n","    corners = corners.reshape(-1,2)\n","    corners = np.hstack((corners, np.ones((corners.shape[0],1), dtype = type(corners[0][0]))))\n","    \n","    M = cv2.getRotationMatrix2D((cx, cy), angle, 1.0)\n","    \n","    \n","    cos = np.abs(M[0, 0])\n","    sin = np.abs(M[0, 1])\n","    \n","    nW = int((h * sin) + (w * cos))\n","    nH = int((h * cos) + (w * sin))\n","    # adjust the rotation matrix to take into account translation\n","    M[0, 2] += (nW / 2) - cx\n","    M[1, 2] += (nH / 2) - cy\n","    # Prepare the vector to be transformed\n","    calculated = np.dot(M,corners.T).T\n","    \n","    calculated = calculated.reshape(-1,8)\n","    \n","    return calculated\n","\n","def get_enclosing_box(corners):\n","    \"\"\"Get an enclosing box for ratated corners of a bounding box\n","    \n","    Parameters\n","    ----------\n","    \n","    corners : numpy.ndarray\n","        Numpy array of shape `N x 8` containing N bounding boxes each described by their \n","        corner co-ordinates `x1 y1 x2 y2 x3 y3 x4 y4`  \n","    \n","    Returns \n","    -------\n","    \n","    numpy.ndarray\n","        Numpy array containing enclosing bounding boxes of shape `N X 4` where N is the \n","        number of bounding boxes and the bounding boxes are represented in the\n","        format `x1 y1 x2 y2`\n","        \n","    \"\"\"\n","    x_ = corners[:,[0,2,4,6]]\n","    y_ = corners[:,[1,3,5,7]]\n","    \n","    xmin = np.min(x_,1).reshape(-1,1)\n","    ymin = np.min(y_,1).reshape(-1,1)\n","    xmax = np.max(x_,1).reshape(-1,1)\n","    ymax = np.max(y_,1).reshape(-1,1)\n","    \n","    final = np.hstack((xmin, ymin, xmax, ymax,corners[:,8:]))\n","    \n","    return final\n","\n","def letterbox_image(img, inp_dim):\n","    '''resize image with unchanged aspect ratio using padding'''\n","    img_w, img_h = img.shape[1], img.shape[0]\n","    w, h = inp_dim\n","    new_w = int(img_w * min(w/img_w, h/img_h))\n","    new_h = int(img_h * min(w/img_w, h/img_h))\n","\n","    resized_image = cv2.resize(img, (new_w,new_h), interpolation = cv2.INTER_CUBIC)\n","\n","    #create a black canvas    \n","    canvas = np.full((inp_dim[1], inp_dim[0], 3), 128)\n"," \n","\t#paste the image on the canvas\n","    canvas[(h-new_h)//2:(h-new_h)//2 + new_h,(w-new_w)//2:(w-new_w)//2 + new_w,  :] = resized_image\n","    \n","    return canvas"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eIsjdfhw9ytV"},"source":["## Random Horizontal Flip\n","\n","The new coordinates of each corner can be then described as the mirror image of the corner in the vertical line passing through the center of the image. For the mathematically inclined, the vertical line passing through the center would be the perpendicular bisector of the line joining the original corner and the new, transformed corner."]},{"cell_type":"code","metadata":{"id":"OpLrUqoQ9whG","executionInfo":{"status":"ok","timestamp":1605823323160,"user_tz":420,"elapsed":1154,"user":{"displayName":"Benjamin Brokaw","photoUrl":"","userId":"17754752755213511475"}}},"source":["class RandomHorizontalFlip(object):\n","    \n","    \"\"\"Randomly horizontally flips the Image with the probability *p*\n","    \n","    Usage\n","    ----------\n","    hor_flip = RandomHorizontalFlip(1)  \n","    img, bboxes = hor_flip(img, bboxes)\n","    plt.imshow(draw_rect(img, bboxes))\n","\n","\n","    Parameters\n","    ----------\n","    p: float\n","        The probability with which the image is flipped\n","        \n","        \n","    Returns\n","    -------\n","    \n","    numpy.ndaaray\n","        Flipped image in the numpy format of shape `HxWxC`\n","    \n","    numpy.ndarray\n","        Tranformed bounding box co-ordinates of the format `n x 4` where n is \n","        number of bounding boxes and 4 represents `x1,y1,x2,y2` of the box\n","        \n","    \"\"\"\n","\n","    def __init__(self, p=0.5):\n","        self.p = p\n","\n","    def __call__(self, img, bboxes):\n","        img_center = np.array(img.shape[:2])[::-1]/2\n","        img_center = np.hstack((img_center, img_center))\n","        if random.random() < self.p:\n","            img =  img[:,::-1,:]\n","            bboxes[:,[0,2]] += 2*(img_center[[0,2]] - bboxes[:,[0,2]])\n","            \n","            box_w = abs(bboxes[:,0] - bboxes[:,2])\n","             \n","            bboxes[:,0] -= box_w\n","            bboxes[:,2] += box_w\n","            \n","        return img, bboxes"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SLfhc4pK-RJC"},"source":["## Random Scale"]},{"cell_type":"code","metadata":{"id":"_F0OZux2-VkU","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"error","timestamp":1605823323165,"user_tz":420,"elapsed":1156,"user":{"displayName":"Benjamin Brokaw","photoUrl":"","userId":"17754752755213511475"}},"outputId":"93e48242-e611-4ee4-bac1-7793d50884a6"},"source":["class RandomScale(object):\n","    \"\"\"Randomly scales an image    \n","    \n","    Bounding boxes which have an area of less than 25% in the remaining in the \n","    transformed image is dropped. The resolution is maintained, and the remaining\n","    area if any is filled by black color.\n","    \n","    Parameters\n","    ----------\n","    scale: float or tuple(float)\n","        if **float**, the image is scaled by a factor drawn \n","        randomly from a range (1 - `scale` , 1 + `scale`). If **tuple**,\n","        the `scale` is drawn randomly from values specified by the \n","        tuple\n","        \n","    Returns\n","    -------\n","    \n","    numpy.ndaaray\n","        Scaled image in the numpy format of shape `HxWxC`\n","    \n","    numpy.ndarray\n","        Tranformed bounding box co-ordinates of the format `n x 4` where n is \n","        number of bounding boxes and 4 represents `x1,y1,x2,y2` of the box\n","        \n","    \"\"\"\n","\n","    def __init__(self, scale = 0.2, diff = False):\n","        self.scale = scale\n","\n","        \n","        if type(self.scale) == tuple:\n","            assert len(self.scale) == 2, \"Invalid range\"\n","            assert self.scale[0] > -1, \"Scale factor can't be less than -1\"\n","            assert self.scale[1] > -1, \"Scale factor can't be less than -1\"\n","        else:\n","            assert self.scale > 0, \"Please input a positive float\"\n","            self.scale = (max(-1, -self.scale), self.scale)\n","        \n","        self.diff = diff\n","\n","    def __call__(self, img, bboxes):\n","\t#Chose a random digit to scale by \n","\n","\timg_shape = img.shape\n","\n","\tif self.diff:\n","\t\tscale_x = random.uniform(*self.scale)\n","\t\tscale_y = random.uniform(*self.scale)\n","\telse:\n","\t\tscale_x = random.uniform(*self.scale)\n","\t\tscale_y = scale_x\n","\n","    resize_scale_x = 1 + scale_x\n","    resize_scale_y = 1 + scale_y\n","\n","    img=  cv2.resize(img, None, fx = resize_scale_x, fy = resize_scale_y)\n","\n","    bboxes[:,:4] *= [resize_scale_x, resize_scale_y, resize_scale_x, resize_scale_y]\n","\n","\n","\n","    canvas = np.zeros(img_shape, dtype = np.uint8)\n","\n","    y_lim = int(min(resize_scale_y,1)*img_shape[0])\n","    x_lim = int(min(resize_scale_x,1)*img_shape[1])\n","\n","    print(y_lim, x_lim)\n","\n","    canvas[:y_lim,:x_lim,:] =  img[:y_lim,:x_lim,:]\n","\n","    img = canvas\n","    bboxes = clip_box(bboxes, [0,0,1 + img_shape[1], img_shape[0]], 0.25)\n","\n","\n","    return img, bboxes"],"execution_count":4,"outputs":[{"output_type":"error","ename":"TabError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-26699420045c>\"\u001b[0;36m, line \u001b[0;32m45\u001b[0m\n\u001b[0;31m    img_shape = img.shape\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"]}]},{"cell_type":"markdown","metadata":{"id":"SR27hgHg_ykp"},"source":["## Translate"]},{"cell_type":"code","metadata":{"id":"6awU6yrv_02d","executionInfo":{"status":"aborted","timestamp":1605823323161,"user_tz":420,"elapsed":1150,"user":{"displayName":"Benjamin Brokaw","photoUrl":"","userId":"17754752755213511475"}}},"source":["class RandomTranslate(object):\n","    \"\"\"Randomly Translates the image    \n","    \n","    \n","    Bounding boxes which have an area of less than 25% in the remaining in the \n","    transformed image is dropped. The resolution is maintained, and the remaining\n","    area if any is filled by black color.\n","    \n","    Parameters\n","    ----------\n","    translate: float or tuple(float)\n","        if **float**, the image is translated by a factor drawn \n","        randomly from a range (1 - `translate` , 1 + `translate`). If **tuple**,\n","        `translate` is drawn randomly from values specified by the \n","        tuple\n","        \n","    Returns\n","    -------\n","    \n","    numpy.ndaaray\n","        Translated image in the numpy format of shape `HxWxC`\n","    \n","    numpy.ndarray\n","        Tranformed bounding box co-ordinates of the format `n x 4` where n is \n","        number of bounding boxes and 4 represents `x1,y1,x2,y2` of the box\n","        \n","    \"\"\"\n","\n","    def __init__(self, translate = 0.2, diff = False):\n","        self.translate = translate\n","        \n","        if type(self.translate) == tuple:\n","            assert len(self.translate) == 2, \"Invalid range\"  \n","            assert self.translate[0] > 0 & self.translate[0] < 1\n","            assert self.translate[1] > 0 & self.translate[1] < 1\n","\n","\n","        else:\n","            assert self.translate > 0 & self.translate < 1\n","            self.translate = (-self.translate, self.translate)\n","            \n","            \n","        self.diff = diff\n","\n","    def __call__(self, img, bboxes):        \n","        img_shape = img.shape\n","        #translate the image\n","        #percentage of the dimension of the image to translate\n","        translate_factor_x = random.uniform(*self.translate)\n","        translate_factor_y = random.uniform(*self.translate)\n","        \n","        if not self.diff:\n","            translate_factor_y = translate_factor_x\n","            \n","        canvas = np.zeros(img_shape).astype(np.uint8)\n","        corner_x = int(translate_factor_x*img.shape[1])\n","        corner_y = int(translate_factor_y*img.shape[0])\n","        \n","        #change the origin to the top-left corner of the translated box\n","        orig_box_cords =  [max(0,corner_y), max(corner_x,0), min(img_shape[0], corner_y + img.shape[0]), min(img_shape[1],corner_x + img.shape[1])]\n","\n","        mask = img[max(-corner_y, 0):min(img.shape[0], -corner_y + img_shape[0]), max(-corner_x, 0):min(img.shape[1], -corner_x + img_shape[1]),:]\n","        canvas[orig_box_cords[0]:orig_box_cords[2], orig_box_cords[1]:orig_box_cords[3],:] = mask\n","        img = canvas\n","        \n","        bboxes[:,:4] += [corner_x, corner_y, corner_x, corner_y]\n","        bboxes = clip_box(bboxes, [0,0,img_shape[1], img_shape[0]], 0.25)\n","        \n","        return img, bboxes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V5tcSzZ7Aq5o"},"source":["## Rotation"]},{"cell_type":"code","metadata":{"id":"0m5iqszHAvyI","executionInfo":{"status":"aborted","timestamp":1605823323163,"user_tz":420,"elapsed":1150,"user":{"displayName":"Benjamin Brokaw","photoUrl":"","userId":"17754752755213511475"}}},"source":["class RandomRotation(object):\n","    \"\"\"Randomly Rotates the image    \n","    \n","    \n","    Bounding boxes which have an area of less than 25% in the remaining in the \n","    transformed image is dropped. The resolution is maintained, and the remaining\n","    area if any is filled by black color.\n","    \n","    Usage\n","    ----------\n","    rotate = RandomRotate(20)  \n","    img, bboxes = rotate(img, bboxes)\n","    plt.imshow(draw_rect(img, bboxes))\n","\n","\n","    Parameters\n","    ----------\n","    translate: float or tuple(float)\n","        if **float**, the image is translated by a factor drawn \n","        randomly from a range (1 - `translate` , 1 + `translate`). If **tuple**,\n","        `translate` is drawn randomly from values specified by the \n","        tuple\n","        \n","    Returns\n","    -------\n","    \n","    numpy.ndaaray\n","        Translated image in the numpy format of shape `HxWxC`\n","    \n","    numpy.ndarray\n","        Tranformed bounding box co-ordinates of the format `n x 4` where n is \n","        number of bounding boxes and 4 represents `x1,y1,x2,y2` of the box\n","        \n","    \"\"\"\n","    def __init__(self, angle = 10):\n","        self.angle = angle\n","        \n","        if type(self.angle) == tuple:\n","            assert len(self.angle) == 2, \"Invalid range\"   \n","        else:\n","            self.angle = (-self.angle, self.angle)\n","\n","    def __call__(self, img, bboxes):\n","\n","        angle = random.uniform(*self.angle)\n","\n","        w,h = img.shape[1], img.shape[0]\n","        cx, cy = w//2, h//2\n","        img = rotate_im(img, angle)\n","\n","        corners = get_corners(bboxes)\n","        corners = np.hstack((corners, bboxes[:,4:]))\n","        corners[:,:8] = rotate_box(corners[:,:8], angle, cx, cy, h, w)\n","        new_bbox = get_enclosing_box(corners)\n","\n","        scale_factor_x = img.shape[1] / w\n","        scale_factor_y = img.shape[0] / h\n","        img = cv2.resize(img, (w,h))\n","\n","        new_bbox[:,:4] /= [scale_factor_x, scale_factor_y, scale_factor_x, scale_factor_y] \n","        bboxes  = new_bbox\n","        bboxes = clip_box(bboxes, [0,0,w, h], 0.25)\n","\n","        return img, bboxes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"weDUcTpFBiUZ"},"source":["## Shearing"]},{"cell_type":"code","metadata":{"id":"N0w87FGqBmtj","executionInfo":{"status":"aborted","timestamp":1605823323163,"user_tz":420,"elapsed":1147,"user":{"displayName":"Benjamin Brokaw","photoUrl":"","userId":"17754752755213511475"}}},"source":["class RandomShear(object):\n","    \"\"\"Randomly shears an image in horizontal direction   \n","    \n","    Bounding boxes which have an area of less than 25% in the remaining in the \n","    transformed image is dropped. The resolution is maintained, and the remaining\n","    area if any is filled by black color.\n","\n","    Usage\n","    ----------\n","    shear = RandomShear(0.7)\n","    img,bboxes = shear(img, bboxes)\n","    plt.imshow(draw_rect(img, bboxes))\n","    \n","    Parameters\n","    ----------\n","    shear_factor: float or tuple(float)\n","        if **float**, the image is sheared horizontally by a factor drawn \n","        randomly from a range (-`shear_factor`, `shear_factor`). If **tuple**,\n","        the `shear_factor` is drawn randomly from values specified by the \n","        tuple\n","        \n","    Returns\n","    -------\n","    \n","    numpy.ndaaray\n","        Sheared image in the numpy format of shape `HxWxC`\n","    \n","    numpy.ndarray\n","        Tranformed bounding box co-ordinates of the format `n x 4` where n is \n","        number of bounding boxes and 4 represents `x1,y1,x2,y2` of the box\n","        \n","    \"\"\"\n","\n","    def __init__(self, shear_factor = 0.2):\n","        self.shear_factor = shear_factor\n","        \n","        if type(self.shear_factor) == tuple:\n","            assert len(self.shear_factor) == 2, \"Invalid range for scaling factor\"   \n","        else:\n","            self.shear_factor = (-self.shear_factor, self.shear_factor)\n","        \n","        shear_factor = random.uniform(*self.shear_factor)\n","\n","    def __call__(self, img, bboxes):\n","\n","        shear_factor = random.uniform(*self.shear_factor)\n","        w,h = img.shape[1], img.shape[0]\n","        if shear_factor < 0:\n","            img, bboxes = HorizontalFlip()(img, bboxes)\n","\n","        M = np.array([[1, abs(shear_factor), 0],[0,1,0]])\n","        nW =  img.shape[1] + abs(shear_factor*img.shape[0])\n","        bboxes[:,[0,2]] += ((bboxes[:,[1,3]]) * abs(shear_factor) ).astype(int) \n","\n","        img = cv2.warpAffine(img, M, (int(nW), img.shape[0]))\n","\n","        if shear_factor < 0:\n","            img, bboxes = HorizontalFlip()(img, bboxes)\n","\n","        img = cv2.resize(img, (w,h))\n","        scale_factor_x = nW / w\n","        bboxes[:,:4] /= [scale_factor_x, 1, scale_factor_x, 1] \n","\n","        return img, bboxes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nTmpGrmZCc1q"},"source":["# Combing Augmentations"]},{"cell_type":"code","metadata":{"id":"rqCeY_qXCf0Q","executionInfo":{"status":"aborted","timestamp":1605823323163,"user_tz":420,"elapsed":1144,"user":{"displayName":"Benjamin Brokaw","photoUrl":"","userId":"17754752755213511475"}}},"source":["class Sequence(object):\n","\n","    \"\"\"Initialise Sequence object\n","    \n","    Apply a Sequence of transformations to the images/boxes.\n","    \n","    Usage\n","    ----------\n","    transforms = Sequence([RandomHorizontalFlip(1), RandomScale(0.2, diff = True), RandomRotate(10)])\n","    img, bboxes = transforms(img, bboxes)\n","\n","    Parameters\n","    ----------\n","    augemnetations : list \n","        List containing Transformation Objects in Sequence they are to be \n","        applied\n","    \n","    probs : int or list \n","        If **int**, the probability with which each of the transformation will \n","        be applied. If **list**, the length must be equal to *augmentations*. \n","        Each element of this list is the probability with which each \n","        corresponding transformation is applied\n","    \n","    Returns\n","    -------\n","    \n","    Sequence\n","        Sequence Object \n","        \n","    \"\"\"\n","    def __init__(self, augmentations, probs = 1):\n","        \n","        self.augmentations = augmentations\n","        self.probs = probs\n","\n","\n","    def __call__(self, images, bboxes):\n","        for i, augmentation in enumerate(self.augmentations):\n","            if type(self.probs) == list:\n","                prob = self.probs[i]\n","            else:\n","                prob = self.probs\n","                \n","            if random.random() < prob:\n","                images, bboxes = augmentation(images, bboxes)\n","        return images, bboxes"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4iLiEuwlC3DM","executionInfo":{"status":"aborted","timestamp":1605823323165,"user_tz":420,"elapsed":1143,"user":{"displayName":"Benjamin Brokaw","photoUrl":"","userId":"17754752755213511475"}}},"source":["class Resize(object):\n","    \"\"\"Resize the image in accordance to `image_letter_box` function in darknet \n","    \n","    The aspect ratio is maintained. The longer side is resized to the input \n","    size of the network, while the remaining space on the shorter side is filled \n","    with black color. **This should be the last transform**\n","    \n","    \n","    Parameters\n","    ----------\n","    inp_dim : tuple(int)\n","        tuple containing the size to which the image will be resized.\n","        \n","    Returns\n","    -------\n","    \n","    numpy.ndaaray\n","        Sheared image in the numpy format of shape `HxWxC`\n","    \n","    numpy.ndarray\n","        Resized bounding box co-ordinates of the format `n x 4` where n is \n","        number of bounding boxes and 4 represents `x1,y1,x2,y2` of the box\n","        \n","    \"\"\"\n","    \n","    def __init__(self, inp_dim):\n","        self.inp_dim = inp_dim\n","\n","    def __call__(self, img, bboxes):\n","        w,h = img.shape[1], img.shape[0]\n","        img = letterbox_image(img, self.inp_dim)\n","\n","        scale = min(self.inp_dim/h, self.inp_dim/w)\n","        bboxes[:,:4] *= (scale)\n","\n","        new_w = scale*w\n","        new_h = scale*h\n","        inp_dim = self.inp_dim   \n","\n","        del_h = (inp_dim - new_h)/2\n","        del_w = (inp_dim - new_w)/2\n","\n","        add_matrix = np.array([[del_w, del_h, del_w, del_h]]).astype(int)\n","        bboxes[:,:4] += add_matrix\n","        img = img.astype(np.uint8)\n","\n","        return img, bboxes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MYfQWv_sDXqx"},"source":["# Augmenation in Pipeline"]},{"cell_type":"code","metadata":{"id":"3POb6AmNDaX2","executionInfo":{"status":"aborted","timestamp":1605823323301,"user_tz":420,"elapsed":1278,"user":{"displayName":"Benjamin Brokaw","photoUrl":"","userId":"17754752755213511475"}}},"source":["from torchvision.datasets import CocoDetection\n","\n","def transform_annotation(x):\n","    #convert the PIL image to a numpy array\n","    image = np.array(x[0])\n","    \n","    #get the bounding boxes and convert them into 2 corners format\n","    boxes = [a[\"bbox\"] for a in x[1]]\n","    boxes = np.array(boxes)\n","    boxes = boxes.reshape(-1,4)\n","    boxes[:,2] += boxes[:,0]\n","    boxes[:,3] += boxes[:,1]\n","\n","    #grab the classes   \n","    category_ids = np.array([a[\"category_id\"] for a in x[1]]).reshape(-1,1)\n","    ground_truth = np.concatenate([boxes, category_ids], 1).reshape(-1,5)\n","    \n","    return image, ground_truth\n","    \n","\n","class CocoAugment(CocoDetection):\n","\n","\tdef __init__(self, root, annFile, transforms, target_transforms, det_transforms):\n","        \"\"\"\n","        In our new class, we introduce the attribute det_transforms which will be \n","        used to hold the augmentation being applied to the image and the bounding \n","        box.\n","        \"\"\"\n","\t\tsuper(CocoAugment, self).__init__(root, annFile, transforms, target_transforms)\n","\t\tself.det_transforms = det_transforms\n","\n","\tdef __getitem__(self, idx):\n","\t\timg, bboxes = super(CocoAugment, self).__getitem__(idx)\n","\t\tbboxes = transform_annotation(bboxes)\n","\t\timg, bboxes = self.det_transforms(img, bboxes)\n","\t\treturn bboxes\n","\n","\n","\n","\n","\n","det_tran = Sequence([RandomHorizontalFlip(1), RandomScale(0.4, diff = True), RandomRotate(10)])\n","coco_dataset = CocoDetection(root = \"train2017\", annFile = \"annots.json\", det_transforms = det_tran)\n","\n","# for image, annotation in coco_dataset:\n","\t# forward / backward pass"],"execution_count":null,"outputs":[]}]}