{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Faster_RCNN","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"4567766c520541c8a8b2f1aebcfec893":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b362100b82044cb49aa9453c74e92284","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8cea4b2df04c4ef3b46216d475bae737","IPY_MODEL_d84dcde3785c4675be7da8a392152928"]}},"b362100b82044cb49aa9453c74e92284":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8cea4b2df04c4ef3b46216d475bae737":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ce2254a6c65f48a5afd0d8068f40a7f8","_dom_classes":[],"description":" 72%","_model_name":"FloatProgressModel","bar_style":"","max":200,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":145,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a479f618c73e4ee1af2584f4d50b4689"}},"d84dcde3785c4675be7da8a392152928":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_05ba890001c7404bbfe7d6f648b59caa","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 145/200 [10:02:01&lt;3:15:53, 213.71s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a6c7824b70c24e5ead9ebcf068e56416"}},"ce2254a6c65f48a5afd0d8068f40a7f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a479f618c73e4ee1af2584f4d50b4689":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"05ba890001c7404bbfe7d6f648b59caa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a6c7824b70c24e5ead9ebcf068e56416":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"ipxQP3GgYdbt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607964768990,"user_tz":420,"elapsed":839,"user":{"displayName":"Carson Stevens","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_0oYvUVBGdb2NYg8kqCEFgYdcDwse6s0G_88RxA=s64","userId":"00108991392718208205"}},"outputId":"e42f9e73-6626-4904-e971-58f33f3742c3"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TpKFyLlSwsh3","executionInfo":{"status":"ok","timestamp":1607964769573,"user_tz":420,"elapsed":1419,"user":{"displayName":"Carson Stevens","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_0oYvUVBGdb2NYg8kqCEFgYdcDwse6s0G_88RxA=s64","userId":"00108991392718208205"}}},"source":["## DONT CLONE THIS REPO\n","##    it already exists, I have made several changes to the library \n","# %cd /content/drive/MyDrive/CV Final Project\n","# !git clone https://github.com/you359/Keras-FasterRCNN.git"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4LHEYWeSYDgO"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"w3XgL9PNxCul","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607964778524,"user_tz":420,"elapsed":10363,"user":{"displayName":"Carson Stevens","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_0oYvUVBGdb2NYg8kqCEFgYdcDwse6s0G_88RxA=s64","userId":"00108991392718208205"}},"outputId":"0139970e-49df-444b-c2e1-914da0f3bf5e"},"source":["%cd /content/drive/MyDrive/CV Final Project/Keras-FasterRCNN\n","!pip install tensorflow-gpu\n","!pip install -r requirements.txt\n","%cd ..\n","# Fix TensorBoard extension\n","\n","\n","from __future__ import division\n","import random\n","import pprint\n","import sys\n","import time\n","import numpy as np\n","import pickle\n","import os\n","\n","import tensorflow as tf\n","# import tensorflow.compat.v1 as tf\n","# tf.disable_v2_behavior()\n","from keras import backend as K\n","from keras.optimizers import Adam, SGD, RMSprop\n","from keras.layers import Input\n","from keras.models import Model\n","sys.path.append('/content/drive/MyDrive/CV Final Project/Keras-FasterRCNN')\n","from keras_frcnn import config, data_generators\n","from keras_frcnn import losses as klosses\n","import keras_frcnn.roi_helpers as roi_helpers\n","from keras.utils import generic_utils\n","from keras.callbacks import TensorBoard\n","from keras_frcnn.simple_parser import get_data\n","\n","from joblib import load, dump\n","from IPython.display import clear_output\n","from tqdm.auto import tqdm, trange\n","\n","\n","if tf.test.gpu_device_name():\n","    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n","    %load_ext tensorboard\n","    from datetime import datetime\n","    # Tensorboard log\n","    logdir = '/content/drive/MyDrive/CV Final Project/data/tf_logs/resnet_516_logs/'\n","    if not os.path.isdir(logdir):\n","        os.mkdir(logdir)\n","\n","    # Tensorboard log\n","    callback = TensorBoard(logdir)\n","\n","    # Start tensorboard\n","    clear_output()\n","    !nvidia-smi\n","\n","else: print(\"Please install GPU version of TF\")\n","\n","# tensorboard\n","def write_log(callback, names, logs, batch_no):\n","    for name, value in zip(names, logs):\n","        summary = tf.Summary()\n","        summary_value = summary.value.add()\n","        summary_value.simple_value = value\n","        summary_value.tag = name\n","        callback.writer.add_summary(summary, batch_no)\n","        callback.writer.flush()\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mon Dec 14 16:52:58 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    40W / 300W |    317MiB / 16130MiB |      2%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NeHv6fr0oM5a","executionInfo":{"status":"ok","timestamp":1607964778525,"user_tz":420,"elapsed":10362,"user":{"displayName":"Carson Stevens","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_0oYvUVBGdb2NYg8kqCEFgYdcDwse6s0G_88RxA=s64","userId":"00108991392718208205"}}},"source":["output_weight_path ='/content/drive/MyDrive/CV Final Project/models/resnet'\n","transfer_learning_model = 'resnet50' # 'vgg', 'resnet50', 'xception', 'inception_resnet_v2'\n","\n","C = config.Config()\n","C.model_path = output_weight_path\n","C.use_horizontal_flips = False\n","C.use_vertical_flips = True\n","C.rot_90 = bool(True)\n","num_rois = 300\n","C.im_size = 516\n","C.num_rois = int(num_rois)\n","\n","if transfer_learning_model == 'vgg':\n","    C.network = 'vgg'\n","    from keras_frcnn import vgg as nn\n","elif transfer_learning_model == 'resnet50':\n","    from keras_frcnn import resnet as nn\n","    C.network = 'resnet50'\n","elif transfer_learning_model == 'xception':\n","    from keras_frcnn import xception as nn\n","    C.network = 'xception'\n","elif transfer_learning_model == 'inception_resnet_v2':\n","    from keras_frcnn import inception_resnet_v2 as nn\n","    C.network = 'inception_resnet_v2'\n","else:\n","    print('Not a valid model')\n","    raise ValueError\n","\n","# set the path to weights based on backend and model\n","C.base_net_weights = nn.get_weight_path()"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bbaqa_6joURS"},"source":["# Load Data\n","  * Attempts to load dataset dictionaries from memory\n","  * Otherwise it re-creates the dictionaries "]},{"cell_type":"code","metadata":{"id":"GKirs2ZcoT1T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607964778947,"user_tz":420,"elapsed":10782,"user":{"displayName":"Carson Stevens","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_0oYvUVBGdb2NYg8kqCEFgYdcDwse6s0G_88RxA=s64","userId":"00108991392718208205"}},"outputId":"7a43db1e-6557-4039-85e3-ed32f17a55a2"},"source":["gen_path = '/content/drive/MyDrive/CV Final Project/data/dumped_data_gen_vgg516/'\n","try:    # try to load saved dataset objects from memory\n","  all_imgs    = load(os.path.join(gen_path, 'all_imgs.pkl'))\n","  classes_count = load(os.path.join(gen_path, 'classes_count.pkl'))\n","  class_mapping = load(os.path.join(gen_path, 'class_mapping.pkl'))\n","  print('--- LOADED DATA DICTIONARIES ---')\n","except: # If dataset objects dont exist:\n","  print('--- FAILED TO LOAD DATABASE FILES ---')\n","  print('--- Recreating Dictionaries ---')\n","  # parse the original dataset file and create new objects\n","  train_path = '/content/drive/MyDrive/CV Final Project/data/annotations_516.txt'\n","  all_imgs, classes_count, class_mapping = get_data(train_path)\n","  # save dataset objects to memory\n","  dump(all_imgs, os.path.join(gen_path, 'all_imgs.pkl'))\n","  dump(classes_count, os.path.join(gen_path, 'classes_count.pkl'))\n","  dump(class_mapping, os.path.join(gen_path, 'class_mapping.pkl'))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["--- LOADED DATA DICTIONARIES ---\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UGwKHOJsSRnD"},"source":["## Create Generators"]},{"cell_type":"code","metadata":{"id":"uIM6gBMVxzi_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607964779233,"user_tz":420,"elapsed":11062,"user":{"displayName":"Carson Stevens","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_0oYvUVBGdb2NYg8kqCEFgYdcDwse6s0G_88RxA=s64","userId":"00108991392718208205"}},"outputId":"16a97d7d-e8b2-4356-a63e-528f49be2a85"},"source":["if 'bg' not in classes_count:\n","    classes_count['bg'] = 0\n","    class_mapping['bg'] = len(class_mapping)\n","\n","C.class_mapping = class_mapping\n","inv_map = {v: k for k, v in class_mapping.items()}\n","print('Training images per class:')\n","pprint.pprint(classes_count)\n","print('Num classes (including bg) = {}'.format(len(classes_count)))\n","\n","config_output_filename = 'meta'\n","with open(config_output_filename, 'wb') as config_f:\n","    pickle.dump(C, config_f)\n","    print('Config has been written to {}, and can be loaded when testing to ensure correct results'.format(config_output_filename))\n","\n","random.shuffle(all_imgs)\n","num_imgs = len(all_imgs)\n","train_imgs = [s for s in all_imgs if s['imageset'] == 'trainval']\n","test_imgs = [s for s in all_imgs if s['imageset'] == 'test']\n","print('Num train samples {}'.format(len(train_imgs)))\n","print('Num test samples {}'.format(len(test_imgs)))\n","\n","# groundtruth anchor \n","data_gen_train = data_generators.get_anchor_gt(train_imgs, classes_count, C, nn.get_img_output_length, K.image_dim_ordering(), mode='train')\n","data_gen_test = data_generators.get_anchor_gt(test_imgs, classes_count, C, nn.get_img_output_length, K.image_dim_ordering(), mode='test')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Training images per class:\n","{'bg': 0, 'mountain': 26797}\n","Num classes (including bg) = 2\n","Config has been written to meta, and can be loaded when testing to ensure correct results\n","Num train samples 9803\n","Num test samples 1907\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pnRKlnXDSmG2"},"source":["# Create Models"]},{"cell_type":"code","metadata":{"id":"U9xC9N-SSlNW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607964788471,"user_tz":420,"elapsed":20294,"user":{"displayName":"Carson Stevens","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_0oYvUVBGdb2NYg8kqCEFgYdcDwse6s0G_88RxA=s64","userId":"00108991392718208205"}},"outputId":"4774937a-6b3c-4585-f41f-cbead5af9bad"},"source":["if K.image_dim_ordering() == 'th': \n","    input_shape_img = (3, None, None)\n","else: \n","    input_shape_img = (None, None, 3)\n","# print(input_shape_img)\n","\n","# input placeholder\n","img_input = Input(shape=input_shape_img)\n","roi_input = Input(shape=(None, 4))\n","\n","# base network(feature extractor) (resnet, VGG, Inception, Inception Resnet V2, etc)\n","shared_layers = nn.nn_base(img_input, trainable=True)\n","\n","# define the RPN, built on the base layers\n","num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n","rpn = nn.rpn(shared_layers, num_anchors)\n","\n","# detection network\n","classifier = nn.classifier(shared_layers, roi_input, C.num_rois, nb_classes=len(classes_count), trainable=True)\n","model_rpn = Model(img_input, rpn[:2])\n","model_classifier = Model([img_input, roi_input], classifier)\n","\n","# this is a model that holds both the RPN and the classifier, used to load/save weights for the models\n","model_all = Model([img_input, roi_input], rpn[:2] + classifier)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:47: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:351: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3176: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3043: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3153: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/CV Final Project/Keras-FasterRCNN/keras_frcnn/RoiPoolingConv.py:108: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3045: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1064: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7EoDqtskSzjJ"},"source":["## Load Pre-Trained Weights"]},{"cell_type":"code","metadata":{"id":"0yQWB167SthF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607964792536,"user_tz":420,"elapsed":24357,"user":{"displayName":"Carson Stevens","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_0oYvUVBGdb2NYg8kqCEFgYdcDwse6s0G_88RxA=s64","userId":"00108991392718208205"}},"outputId":"2020583c-4a8e-4cfd-825b-be9d8cb47f53"},"source":["try:\n","    # load_weights by name\n","    # some keras application model does not containing name\n","    # for this kinds of model, we need to re-construct model with naming\n","    print('loading weights from {}'.format(C.base_net_weights))\n","    model_rpn.load_weights('/content/drive/MyDrive/CV Final Project/models/resnet/resnet516_300roi_best_loss.ckpt', by_name=True)\n","    # model_rpn.load_weights('/content/drive/MyDrive/CV Final Project/Keras-FasterRCNN/resnet50_weights_tf_dim_ordering_tf_kernels.h5', by_name=True)\n","    print('{} rpn model weights loaded'.format(C.base_net_weights))\n","    model_classifier.load_weights('/content/drive/MyDrive/CV Final Project/models/resnet/resnet516_300roi_best_loss.ckpt', by_name=True)\n","    # model_classifier.load_weights('/content/drive/MyDrive/CV Final Project/Keras-FasterRCNN/resnet50_weights_tf_dim_ordering_tf_kernels.h5', by_name=True)\n","    print('{} classifier model weights loaded'.format(C.base_net_weights))\n","except Exception as e:\n","    print(e)\n","    print('Could not load pretrained model weights. Weights can be found in the keras application folder \\\n","        https://github.com/fchollet/keras/tree/master/keras/applications')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["loading weights from resnet50_weights_tf_dim_ordering_tf_kernels.h5\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:141: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","resnet50_weights_tf_dim_ordering_tf_kernels.h5 rpn model weights loaded\n","resnet50_weights_tf_dim_ordering_tf_kernels.h5 classifier model weights loaded\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UDfejAzbSwh_"},"source":["## Compile Models"]},{"cell_type":"code","metadata":{"id":"YPMt9GQtSvU8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607964792537,"user_tz":420,"elapsed":24356,"user":{"displayName":"Carson Stevens","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_0oYvUVBGdb2NYg8kqCEFgYdcDwse6s0G_88RxA=s64","userId":"00108991392718208205"}},"outputId":"5191be4f-f537-4bd0-e40c-87387af77dd9"},"source":["optimizer = Adam(lr=1e-5)\n","optimizer_classifier = Adam(lr=1e-5)\n","model_rpn.compile(optimizer=optimizer, loss=[klosses.rpn_loss_cls(num_anchors), klosses.rpn_loss_regr(num_anchors)])\n","model_classifier.compile(optimizer=optimizer_classifier, loss=[klosses.class_loss_cls, klosses.class_loss_regr(len(classes_count)-1)], metrics={'dense_class_{}'.format(len(classes_count)): 'accuracy'})\n","model_all.compile(optimizer='sgd', loss='mae')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:675: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1046: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n","Instructions for updating:\n","keep_dims is deprecated, use keepdims instead\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8qzsFZtcS7x0"},"source":["### Model Summaries"]},{"cell_type":"code","metadata":{"id":"9jw5cftD5IcV","executionInfo":{"status":"ok","timestamp":1607964792537,"user_tz":420,"elapsed":24354,"user":{"displayName":"Carson Stevens","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_0oYvUVBGdb2NYg8kqCEFgYdcDwse6s0G_88RxA=s64","userId":"00108991392718208205"}}},"source":["# RPN model\n","# model_rpn.summary()\n","\n","# Classifier model\n","# model_classifier.summary()\n","\n","# model that holds both the RPN and the classifier\n","# model_all.summary()"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gBtCpDLUTHm-"},"source":["# Train Model"]},{"cell_type":"code","metadata":{"id":"RpcCYqkj3fZg","colab":{"resources":{"http://localhost:6006/":{"data":"CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNTAwIChJbnRlcm5hbCBTZXJ2ZXIgRXJyb3IpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj41MDAuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K","ok":false,"headers":[["content-length","1461"],["content-type","text/html; charset=utf-8"]],"status":500,"status_text":""}},"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1607964792554,"user_tz":420,"elapsed":24370,"user":{"displayName":"Carson Stevens","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg_0oYvUVBGdb2NYg8kqCEFgYdcDwse6s0G_88RxA=s64","userId":"00108991392718208205"}},"outputId":"fab10888-b247-4e5a-cf0e-3401b14bf29f"},"source":["%tensorboard --logdir /content/drive/MyDrive/CV\\ Final\\ Project/data/tf_logs/resnet_516_logs"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["Reusing TensorBoard on port 6006 (pid 396), started 0:07:56 ago. (Use '!kill 396' to kill it.)"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","    <div id=\"root\"></div>\n","    <script>\n","      (function() {\n","        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n","        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n","        document.querySelector(\"base\").href = \"https://localhost:6006\";\n","        function fixUpTensorboard(root) {\n","          const tftb = root.querySelector(\"tf-tensorboard\");\n","          // Disable the fragment manipulation behavior in Colab. Not\n","          // only is the behavior not useful (as the iframe's location\n","          // is not visible to the user), it causes TensorBoard's usage\n","          // of `window.replace` to navigate away from the page and to\n","          // the `localhost:<port>` URL specified by the base URI, which\n","          // in turn causes the frame to (likely) crash.\n","          tftb.removeAttribute(\"use-hash\");\n","        }\n","        function executeAllScripts(root) {\n","          // When `script` elements are inserted into the DOM by\n","          // assigning to an element's `innerHTML`, the scripts are not\n","          // executed. Thus, we manually re-insert these scripts so that\n","          // TensorBoard can initialize itself.\n","          for (const script of root.querySelectorAll(\"script\")) {\n","            const newScript = document.createElement(\"script\");\n","            newScript.type = script.type;\n","            newScript.textContent = script.textContent;\n","            root.appendChild(newScript);\n","            script.remove();\n","          }\n","        }\n","        function setHeight(root, height) {\n","          // We set the height dynamically after the TensorBoard UI has\n","          // been initialized. This avoids an intermediate state in\n","          // which the container plus the UI become taller than the\n","          // final width and cause the Colab output frame to be\n","          // permanently resized, eventually leading to an empty\n","          // vertical gap below the TensorBoard UI. It's not clear\n","          // exactly what causes this problematic intermediate state,\n","          // but setting the height late seems to fix it.\n","          root.style.height = `${height}px`;\n","        }\n","        const root = document.getElementById(\"root\");\n","        fetch(\".\")\n","          .then((x) => x.text())\n","          .then((html) => void (root.innerHTML = html))\n","          .then(() => fixUpTensorboard(root))\n","          .then(() => executeAllScripts(root))\n","          .then(() => setHeight(root, 800));\n","      })();\n","    </script>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"-mZEV2Ha4sdw","colab":{"base_uri":"https://localhost:8080/","height":268,"referenced_widgets":["4567766c520541c8a8b2f1aebcfec893","b362100b82044cb49aa9453c74e92284","8cea4b2df04c4ef3b46216d475bae737","d84dcde3785c4675be7da8a392152928","ce2254a6c65f48a5afd0d8068f40a7f8","a479f618c73e4ee1af2584f4d50b4689","05ba890001c7404bbfe7d6f648b59caa","a6c7824b70c24e5ead9ebcf068e56416"]},"outputId":"4f8cf4d9-59ff-4ae3-bfca-4251c3b41d04"},"source":["callback.set_model(model_all)\n","\n","epoch_length = 500\n","num_epochs = 200\n","iter_num = 0\n","train_step = 0\n","\n","losses = np.zeros((epoch_length, 5))\n","rpn_accuracy_rpn_monitor = []\n","rpn_accuracy_for_epoch = []\n","start_time = time.time()\n","\n","best_loss = 0.3763733365619294\n","\n","class_mapping_inv = {v: k for k, v in class_mapping.items()}\n","\n","C.verbose = True\n","print('Starting training')\n","import time\n","for epoch_num in (trange(num_epochs)):\n","\n","    progbar = generic_utils.Progbar(epoch_length)\n","    print('Epoch {}/{}'.format(epoch_num + 1, num_epochs))\n","\n","    while True:\n","        try:\n","            # mean overlapping bboxes\n","            if len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n","                mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n","                rpn_accuracy_rpn_monitor = []\n","                print('Average number of overlapping bounding boxes from RPN = {} for {} previous iterations'.format(mean_overlapping_bboxes, epoch_length))\n","                if mean_overlapping_bboxes == 0:\n","                    print('RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n","\n","            X, Y, img_data = next(data_gen_train)\n","            # print('Y.shape:')\n","            # print(Y_cls.shape)\n","            # print(Y_rpn.shape)\n","  \n","            loss_rpn = model_rpn.train_on_batch(X, Y)\n","            write_log(callback, ['rpn_cls_loss', 'rpn_reg_loss'], loss_rpn, train_step)\n","  \n","            P_rpn = model_rpn.predict_on_batch(X)\n","            R = roi_helpers.rpn_to_roi(P_rpn[0], P_rpn[1], C, K.image_dim_ordering(), use_regr=True, overlap_thresh=0.7, max_boxes=300)\n","            # note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n","            X2, Y1, Y2, IouS = roi_helpers.calc_iou(R, img_data, C, class_mapping)\n","  \n","            if X2 is None:\n","                # if C.verbose: print('none')\n","                rpn_accuracy_rpn_monitor.append(0)\n","                rpn_accuracy_for_epoch.append(0)\n","                continue\n","  \n","            # sampling positive/negative samples\n","            neg_samples = np.where(Y1[0, :, -1] == 1)\n","            pos_samples = np.where(Y1[0, :, -1] == 0)\n","  \n","            if len(neg_samples) > 0: neg_samples = neg_samples[0]\n","            else: neg_samples = []\n","  \n","            if len(pos_samples) > 0: pos_samples = pos_samples[0]\n","            else: pos_samples = []\n","  \n","            rpn_accuracy_rpn_monitor.append(len(pos_samples))\n","            rpn_accuracy_for_epoch.append((len(pos_samples)))\n","  \n","            if C.num_rois > 1:\n","                if len(pos_samples) < C.num_rois//2:\n","                    selected_pos_samples = pos_samples.tolist()\n","                else:\n","                    if len(pos_samples) > 0:\n","                        selected_pos_samples = np.random.choice(pos_samples, C.num_rois//2, replace=False).tolist()\n","                    else: selected_pos_samples = []\n","                try:\n","                    if len(neg_samples) > 0:\n","                        selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=False).tolist()\n","                    else: selected_neg_samples = []\n","                except:\n","                    if len(neg_samples) > 0:\n","                        selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=True).tolist()\n","                    else: selected_neg_samples = []\n","                sel_samples = selected_pos_samples + selected_neg_samples\n","            else:\n","                # in the extreme case where num_rois = 1, we pick a random pos or neg sample\n","                selected_pos_samples = pos_samples.tolist()\n","                selected_neg_samples = neg_samples.tolist()\n","                if np.random.randint(0, 2): sel_samples = random.choice(neg_samples)\n","                else: sel_samples = random.choice(pos_samples)\n","\n","            loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n","            write_log(callback, ['detection_cls_loss', 'detection_reg_loss', 'detection_acc'], loss_class, train_step)\n","            train_step += 1\n","  \n","            losses[iter_num, 0] = loss_rpn[1]\n","            losses[iter_num, 1] = loss_rpn[2]\n","\n","            losses[iter_num, 2] = loss_class[1]\n","            losses[iter_num, 3] = loss_class[2]\n","            losses[iter_num, 4] = loss_class[3]\n","  \n","            iter_num += 1\n","            progbar.update(iter_num, [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n","                                    ('detector_cls', np.mean(losses[:iter_num, 2])), ('detector_regr', np.mean(losses[:iter_num, 3]))])\n","  \n","            if iter_num == epoch_length:\n","                loss_rpn_cls = np.mean(losses[:, 0])\n","                loss_rpn_regr = np.mean(losses[:, 1])\n","                loss_class_cls = np.mean(losses[:, 2])\n","                loss_class_regr = np.mean(losses[:, 3])\n","                class_acc = np.mean(losses[:, 4])\n","  \n","                mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n","                rpn_accuracy_for_epoch = []\n","  \n","                if C.verbose:\n","                    clear_output()\n","                    print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n","                    print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n","                    print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n","                    print('Loss RPN regression: {}'.format(loss_rpn_regr))\n","                    print('Loss Detector classifier: {}'.format(loss_class_cls))\n","                    print('Loss Detector regression: {}'.format(loss_class_regr))\n","                    print('Elapsed time: {}'.format(time.time() - start_time))\n","  \n","                curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n","                iter_num = 0\n","                start_time = time.time()\n","  \n","                write_log(callback,\n","                          ['Elapsed_time', 'mean_overlapping_bboxes',\n","                           'mean_rpn_cls_loss', 'mean_rpn_reg_loss',\n","                           'mean_detection_cls_loss', 'mean_detection_reg_loss',\n","                           'mean_detection_acc', 'total_loss'],\n","                          [time.time() - start_time, mean_overlapping_bboxes,\n","                           loss_rpn_cls, loss_rpn_regr,\n","                           loss_class_cls, loss_class_regr,\n","                           class_acc, curr_loss],\n","                           epoch_num)\n","                if best_loss == 0:\n","                    best_loss = curr_loss\n","                    print(\"Total loss is {}\". format(best_loss))\n","                if curr_loss < best_loss:\n","                    if C.verbose: print('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n","                    best_loss = curr_loss\n","                    # save_file= os.path.join(C.model_path, datetime.now().strftime(\"%Y%m%d-%H%M%S\")+ '.ckpt')\n","                    save_file= os.path.join(C.model_path, 'resnet516_300roi_best_loss.ckpt')\n","                    model_all.save_weights(save_file)\n","                else:\n","                    print(\"Previous best loss was {}\\nCurrent loss is {}\". format(best_loss, curr_loss))\n","                break\n","\n","                \n","        except Exception as e: continue\n","            # if C.verbose: print(e)\n","\n","print('Training complete, exiting.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mean number of bounding boxes from RPN overlapping ground truth boxes: 2.3405405405405406\n","Classifier accuracy for bounding boxes from RPN: 0.9929133379459381\n","Loss RPN classifier: 0.14158053798300665\n","Loss RPN regression: 0.14358556960721033\n","Loss Detector classifier: 0.026019581065564353\n","Loss Detector regression: 0.09086217337887502\n","Elapsed time: 212.01679754257202\n","Previous best loss was 0.3695394790979608\n","Current loss is 0.40204786203465637\n","Epoch 146/200\n","101/500 [=====>........................] - ETA: 176s - rpn_cls: 0.1320 - rpn_regr: 0.1720 - detector_cls: 0.0231 - detector_regr: 0.0709"],"name":"stdout"}]}]}